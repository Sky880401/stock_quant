import os
from openai import OpenAI
from dotenv import load_dotenv

# è¼‰å…¥ .env è®Šæ•¸
load_dotenv()

class QuantBrain:
    def __init__(self):
        # çµ±ä¸€ä½¿ç”¨ NVIDIA API ä½œç‚ºå”¯ä¸€é‹ç®—ä¸­å¿ƒ
        nv_key = os.getenv("NVIDIA_API_KEY")
        if not nv_key:
            print("âš ï¸ è­¦å‘Š: æœªåµæ¸¬åˆ° NVIDIA_API_KEYï¼Œç³»çµ±ç„¡æ³•é‹ä½œã€‚")
        
        self.client = OpenAI(
            base_url="https://integrate.api.nvidia.com/v1",
            api_key=nv_key
        )

    def analyze_market_report(self, context_data):
        """
        Mode A (æˆ°ç•¥å¤§è…¦): ä½¿ç”¨ Llama 3.1 405B
        ç”¨é€”: ç›¤å¾Œæ·±åº¦åˆ†æã€ç­–ç•¥å›æ¸¬å ±å‘Š
        """
        print("ğŸ§  [Mode A] å‘¼å« NVIDIA (405B) é€²è¡Œæ·±åº¦æˆ°ç•¥åˆ†æ...")
        try:
            response = self.client.chat.completions.create(
                model="meta/llama-3.1-405b-instruct",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯è¯çˆ¾è¡—é ‚å°–é‡åŒ–æ¶æ§‹å¸«ã€‚è«‹æ ¹æ“šå‚³å…¥çš„ JSON æ•¸æ“šï¼Œæ’°å¯«ä¸€ä»½å°ˆæ¥­çš„ Markdown æŠ•è³‡æ—¥å ± (ç¹é«”ä¸­æ–‡)ã€‚é‡é»åˆ†æï¼šå¸‚å ´æƒ…ç·’ã€è¡çªè¨Šè™Ÿ (Technical vs Fundamental)ã€ä»¥åŠå…·é«”çš„è²·è³£å»ºè­° (å«æ­¢æä½)ã€‚"},
                    {"role": "user", "content": context_data}
                ],
                temperature=0.2,  # ä½éš¨æ©Ÿæ€§ï¼Œè¿½æ±‚åš´è¬¹
                max_tokens=4096   # å…è¨±ç”Ÿæˆé•·ç¯‡å ±å‘Š
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ æ·±åº¦åˆ†æå¤±æ•—: {e}"

    def quick_check(self, text):
        """
        Mode B (æˆ°è¡“åŸ·è¡Œ): ä½¿ç”¨ Llama 3.1 70B
        ç”¨é€”: ç›¤ä¸­å³æ™‚å•ç­”ã€Discord æŒ‡ä»¤ã€è¨Šè™Ÿæª¢æŸ¥
        å„ªå‹¢: æ¯” 405B å¿«ï¼Œæ¯” Local 8B è°æ˜éå¸¸å¤š
        """
        print("âš¡ [Mode B] å‘¼å« NVIDIA (70B) é€²è¡Œç›¤ä¸­å³æ™‚æƒæ...")
        try:
            response = self.client.chat.completions.create(
                model="meta/llama-3.1-70b-instruct", 
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯é«˜é »äº¤æ˜“å“¡çš„åŠ©æ‰‹ã€‚è«‹ç”¨ç°¡æ½”ã€æœæ–·çš„èªæ°£ (ç¹é«”ä¸­æ–‡) å›ç­”ç›¤ä¸­æŸ¥è©¢ã€‚è‹¥æ¶‰åŠæ•¸æ“šï¼Œè«‹ç¢ºä¿ç²¾æº–ã€‚"},
                    {"role": "user", "content": text}
                ],
                temperature=0.4, # ä¿æŒéˆæ´»ä½†ä¸éåº¦ç™¼æ•£
                max_tokens=1024  # é™åˆ¶å›æ‡‰é•·åº¦ï¼Œæå‡å›æ‡‰é€Ÿåº¦
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ å³æ™‚åˆ†æå¤±æ•—: {e}"

    def strategy_consult(self, symbol, market_data_text):
        """
        Mode A+ (å–®é»æˆ°ç•¥): æ³¨å…¥å³æ™‚æ•¸æ“š
        """
        print(f"ğŸ§  [Mode A+] å‘¼å« NVIDIA (405B) æ·±åº¦åˆ†æ {symbol}...")
        try:
            # ğŸ‘‡ é—œéµä¿®æ”¹ï¼šå°‡å³æ™‚æ•¸æ“šå¡å…¥ Prompt
            prompt = f"""
            è«‹é‡å° {symbol} é€²è¡Œæ·±åº¦æŠ•è³‡æˆ°ç•¥åˆ†æã€‚
            
            ã€å³æ™‚å¸‚å ´æ•¸æ“šã€‘
            {market_data_text}
            
            ã€åˆ†æè¦æ±‚ã€‘
            1. è«‹**åš´æ ¼åŸºæ–¼ä¸Šè¿°æä¾›çš„æ•¸æ“š**é€²è¡Œåˆ†æï¼Œåš´ç¦ç·¨é€ åƒ¹æ ¼ã€‚
            2. è§£è®€ç›®å‰å¸‚å ´æƒ…ç·’ã€‚
            3. åˆ†ææŠ€è¡“é¢èˆ‡åŸºæœ¬é¢æ˜¯å¦æœ‰è¡çªã€‚
            4. çµ¦å‡ºå…·é«”æ“ä½œå»ºè­° (é€²å ´/æ­¢æ/ç²åˆ©)ï¼Œéœ€ç¬¦åˆç›®å‰è‚¡åƒ¹ä½éšã€‚
            5. ä½¿ç”¨ç¹é«”ä¸­æ–‡ Markdown æ ¼å¼ã€‚
            """
            
            response = self.client.chat.completions.create(
                model="meta/llama-3.1-405b-instruct",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯è¯çˆ¾è¡—å°æ²–åŸºé‡‘çš„é¦–å¸­ç­–ç•¥å¸«ã€‚ä½ å¿…é ˆä¾æ“šä½¿ç”¨è€…æä¾›çš„çœŸå¯¦æ•¸æ“šé€²è¡Œåˆ†æï¼Œä¸å¯ç”¢ç”Ÿå¹»è¦ºã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2048
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ æˆ°ç•¥åˆ†æå¤±æ•—: {e}"