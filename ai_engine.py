import os
from openai import OpenAI
from dotenv import load_dotenv

# è¼‰å…¥ .env è®Šæ•¸
load_dotenv()

class QuantBrain:
    def __init__(self):
        # çµ±ä¸€ä½¿ç”¨ NVIDIA API ä½œç‚ºå”¯ä¸€é‹ç®—ä¸­å¿ƒ
        nv_key = os.getenv("NVIDIA_API_KEY")
        if not nv_key:
            print("âš ï¸ è­¦å‘Š: æœªåµæ¸¬åˆ° NVIDIA_API_KEYï¼Œç³»çµ±ç„¡æ³•é‹ä½œã€‚")
        
        self.client = OpenAI(
            base_url="https://integrate.api.nvidia.com/v1",
            api_key=nv_key
        )

    def analyze_market_report(self, context_data):
        """
        Mode A (é‡å‹å¦å…‹): ä½¿ç”¨ Llama 3.1 405B
        ç”¨é€”: ç›¤å¾Œæ·±åº¦åˆ†æã€ç­–ç•¥å›æ¸¬å ±å‘Š
        """
        print("ğŸ§  [Mode A] å‘¼å« NVIDIA (405B) é€²è¡Œæ·±åº¦æˆ°ç•¥åˆ†æ...")
        try:
            response = self.client.chat.completions.create(
                model="meta/llama-3.1-405b-instruct",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯è¯çˆ¾è¡—é ‚å°–é‡åŒ–æ¶æ§‹å¸«ã€‚è«‹æ ¹æ“šå‚³å…¥çš„ JSON æ•¸æ“šï¼Œæ’°å¯«ä¸€ä»½å°ˆæ¥­çš„ Markdown æŠ•è³‡æ—¥å ± (ç¹é«”ä¸­æ–‡)ã€‚é‡é»åˆ†æï¼šå¸‚å ´æƒ…ç·’ã€è¡çªè¨Šè™Ÿ (Technical vs Fundamental)ã€ä»¥åŠå…·é«”çš„è²·è³£å»ºè­° (å«æ­¢æä½)ã€‚"},
                    {"role": "user", "content": context_data}
                ],
                temperature=0.2, # ä½éš¨æ©Ÿæ€§ï¼Œè¿½æ±‚åš´è¬¹
                max_tokens=2048
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ æ·±åº¦åˆ†æå¤±æ•—: {e}"

    def quick_check(self, text):
        """
        Mode B (å¿«é€Ÿåæ‡‰éƒ¨éšŠ): ä½¿ç”¨ Llama 3.1 70B
        ç”¨é€”: ç›¤ä¸­å³æ™‚å•ç­”ã€Discord æŒ‡ä»¤ã€è¨Šè™Ÿæª¢æŸ¥
        å„ªå‹¢: é€Ÿåº¦æ¯” 405B å¿«ï¼Œæº–åº¦é å‹ Local 8B
        """
        print("âš¡ [Mode B] å‘¼å« NVIDIA (70B) é€²è¡Œç›¤ä¸­å³æ™‚æƒæ...")
        try:
            response = self.client.chat.completions.create(
                # é€™è£¡æ”¹ç”¨ 70B æ¨¡å‹ï¼Œé€Ÿåº¦èˆ‡æ™ºå•†çš„æœ€ä½³å¹³è¡¡é»
                model="meta/llama-3.1-70b-instruct", 
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯é«˜é »äº¤æ˜“å“¡çš„åŠ©æ‰‹ã€‚è«‹ç”¨ç°¡æ½”ã€æœæ–·çš„èªæ°£ (ç¹é«”ä¸­æ–‡) å›ç­”ç›¤ä¸­æŸ¥è©¢ã€‚è‹¥æ¶‰åŠæ•¸æ“šï¼Œè«‹ç¢ºä¿ç²¾æº–ã€‚"},
                    {"role": "user", "content": text}
                ],
                temperature=0.5, # ç¨å¾®éˆæ´»ä¸€é»
                max_tokens=512   # å›ç­”çŸ­ä¸€é»ï¼Œé€Ÿåº¦å„ªå…ˆ
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âŒ å³æ™‚åˆ†æå¤±æ•—: {e}"